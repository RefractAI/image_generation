dataset:
  path: cache256_flowers/combined_dataset
  type: huggingface_disk
  image_size: 256
  multires: false
  batch_size: 8
  max_workers: 32
  latent_field: latents
  caption_field: captions
  alt_caption_field: ""
  alt_caption_min_length: 0
  alt_caption_probability: 0.0
  scale_factor: 8
  image_field: null
model:
  type: DDT
  channels: 4
  n_layers: 18
  n_encoder_layers: 12
  n_heads: 8
  dim: 512
  patch_size: 4
  experiment: multiple_final_layers_with_skip
  num_classes: 1000
  learn_sigma: true
  deep_supervision: 0
  use_cross_attention: true
  num_text_blocks: 4
  use_tread: true
  tread_dropout_ratio: 0.5
  tread_prev_blocks: 3
  tread_post_blocks: 1
vae:
  path: vae
  class_name: AutoencoderKLVAE
text_encoder:
  type: causal_lm
  path: google/gemma-3-270m
  max_length: 4
  txt_embed_dim: 640
optimizer:
  name: adamw
  lr: 0.0001
  warmup_steps: 0
training:
  epochs: 500
  mixed_precision: bf16
  resume: true
  save_every: 1000
  cond_dropout: 0.1
  clip_grad: 1.0
  log_window: 10
  unconditional_caption: ""
sampling:
  interval: 1000
  steps: 50
  num_samples: 8
  cfg: 2.0
logging:
  checkpoints_dir: checkpoints
  samples_dir: samples
  runs_dir: runs
  track_performance: true
loop:
  train_step: default
  sample_step: default
losses:
  mse: 1.0
  cf: -0.05





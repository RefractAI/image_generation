# Training config for ImageNet-1k cached at 256px
#
# Assumes cache was generated to `cache256_imagenet/combined_dataset`
# using `configs/cache_imagenet256.yaml`.

dataset:
  path: cache256_imagenet/combined_dataset
  type: huggingface_disk
  image_size: 256
  multires: false
  batch_size: 256
  max_workers: 32
  latent_field: latents
  caption_field: captions
  alt_caption_field: alt_captions
  alt_caption_min_length: 0
  alt_caption_probability: 1.0
  scale_factor: 8
  image_field: null

model:
  type: ImageModel
  channels: 4
  n_layers: 18
  n_encoder_layers: 16
  n_heads: 16
  dim: 768
  decoder_hidden_size: 64
  num_text_blocks: 2
  patch_size: 2
  use_tread: true
  compile: true
  num_classes: 1000

vae:
  path: vae
  class_name: AutoencoderKLVAE

text_encoder:
  type: c2i
  max_length: 1
  default_label: 0

optimizer:
  name: adamw_fused
  lr: 0.0002
  warmup_steps: 0

training:
  epochs: 500
  mixed_precision: bf16
  resume: true
  save_every: 2000
  cond_dropout: 0.1
  clip_grad: 1.0
  log_window: 10
  unconditional_caption: "1000"

sampling:
  interval: 2000
  steps: 50
  num_samples: 12
  cfg: 2.0

logging:
  checkpoints_dir: checkpoints
  samples_dir: samples
  runs_dir: runs
  track_performance: false

loop:
  train_step: default
  sample_step: default

losses:
  mse: 1.0
  cf: -0.05
